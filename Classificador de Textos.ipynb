{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "O presente projeto possui como objetivo realizar a classificação de palavras de um Dataset com opiniões de produtos das Lojas Americanas. Partindo de uma lista de comentários com notas iniciais de 1 a 5 estrelas para cada produto, treinaremos nosso modelo de classificação de texto para correlacionar as tokens e frases dos respectivos comentários a uma **categoria final positiva ou negativa**.\n",
    "\n",
    "# Dataset\n",
    "O Dataset de avaliações de produtos do site americanas.com.br encontra-se em `./Bases/dados_americanas.xlsx`, e contém as seguintes colunas: \n",
    "* `submission_date` (data de submissão) \n",
    "* `reviewer_id` (id do usuário) \n",
    "* `product_id` (id do produto)\n",
    "* `product_name` (nome do produto)\n",
    "* `product_brand` (marca do produto)\n",
    "* `site_category_lv1` e `site_category_lv2` (categorias do produto)\n",
    "* `review_title` (título do comentário)\n",
    "* `overall_rating` (classificação de 1 a 5)\n",
    "* `recommend_to_a_friend` (recomenda a um amigo)\n",
    "* `review_text` (texto do comentário)\n",
    "* `reviewer_birth_year` (ano de nascimento do usuário)\n",
    "* `reviewer_gender` (sexo do usuário)\n",
    "* `reviewer_state` (estado do usuário)\n",
    "\n",
    "Para o nosso estudo, apenas as colunas `review_text` e `overall_rating` são suficientes. Nosso repositório também possui um dataset com as mesmas colunas localizado em `./Bases/teste_dataset.csv`, para que possamos avaliar o modelo criado posteriormente com casos de testes. Os datasets foram obtidos a partir das seguintes fontes:\n",
    "\n",
    "Dataset Americanas: https://github.com/b2wdigital/b2w-reviews01 (B2W-Reviews01.csv)\n",
    "\n",
    "Dataset de Teste: https://www.kaggle.com/olistbr/brazilian-ecommerce (olist_order_reviews_dataset.csv)\n",
    "\n",
    "# Metodologia\n",
    "Utilizamos uma regressão logística (cujos parâmetros foram escolhidos através do algoritmo GridSearchCV, da biblioteca SKLearn) para classificar os textos em 2 categorias: `0` - Avaliação **Negativa** ou `1` - Avaliação **Positiva**. Primeiramente, foi necessário realizar o pré-processamento dos dados, ou seja, \n",
    "normalizar as palavras dos comentários. Esse procedimento incluiu as seguintes acões: \n",
    "* Retirar acentos e maiúsculas das palavras iniciais, para convergir palavras escritas de forma diferente num mesmo significado;\n",
    "* Substituir emails por um único token indicativo (`_EMAIL_`). Pela definição do problema, a presença de e-mails pode ser relevante para indicar que a avaliação é negativa e, portanto, não excluímos os e-mails, mas sim indicamos que ali foi inserido um;\n",
    "* Substituir pontuações por espaços para evitar junção de palavras. Por exemplo, se um comentário incluísse a frase `adorei,muito bom`, o algoritmo criaria uma palavra `adorei,muito`. Após aplicar a substituição, o resultado da frase seria `adorei muito bom`, permitindo utilizar 3 tokens separados;\n",
    "* Da mesma forma, podem ser desconsiderados números e caracteres especiais pois seus significados variam muito de acordo com a frase em análise;\n",
    "* Tokenização, para quebrar o texto em uma lista de palavras;\n",
    "* Remoção de \"letras soltas\" (`a`, `o`, `e`, etc.), pois fazem pouca ou nenhuma diferença no resultado final, e podem surgir devido à remoção de algum caractere especial (por exemplo, a remoção do cifrão em valores monetários faz com que uma letra r fique isolada no texto). Geralmente são conjunções ou preposições;\n",
    "* Ajustar palavras com letras a mais (`Ruim demaissss` se torna igual à `Ruim demais`);\n",
    "* Substituir abreviações por palavras equivalentes;\n",
    "* Remoção de stopwords. Ex.: `as`, `e`, `os`, `de`, `para`, `com`, `sem`, `foi`;\n",
    "* Aplicação de algoritmo de Stemming para lingua portuguesa para evitar que variações de uma mesma palavra sejam identificadas como diferentes..\n",
    "\n",
    "Nessa etapa, também **removemos todos os comentários com notas igual à 3**, pois eles representavam tanto avaliações muito ruins quanto muito boas. Uma possibilidade que explica isso é que o site automaticamente utilize a nota 3 caso o usuário não forneça alguma manualmente. Assim, classificamos as notas 1 e 2 na categoria `0 - Avaliação Negativa`, e as notas 4 e 5 em `1 - Avaliação Positiva`. Também **retiramos diversas colunas do Dataset**, mantendo apenas as necessárias: `review_text` (renomeada para `Texto`) e a `Classe` binária que criamos.\n",
    "\n",
    "Após isso, obtemos os textos pré-processados e os retornamos. Por exemplo, \n",
    "> MEU FILHO AMOU! PARECE DE VERDADE\n",
    "\n",
    "tornou-se\n",
    "\n",
    "> filh amou parec verdad\n",
    "\n",
    "Realizamos o pré processamento da base e salvamos o resultado em um arquivo `xlsx`, `./Bases/Base_Final.xlsx`, e então aplicamos a regressão logística. \n",
    "\n",
    "## Regressão Logística\n",
    "\n",
    "Utilizando a vetorização utilizando a métrica [TFIDF](https://www.freecodecamp.org/news/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3/) (\"Term frequency - Inverse Data Frequency\"), que representa os textos na forma de um vetor com o tf-idf das palavras, bigramas e trigramas, fomos capazes de realizar o treinamento do algoritmo de **regressão logística** realizando a tunagem dos parâmetros por meio de uma GridSearchCV, por meio da qual encontramos um melhor estimador (estimador com maior F1 score). Para auxiliar com possíveis pré-carregamentos, salvamos o modelo no caminho `./Auxiliar/modelo.pkl` e desenvolvemos uma função para retornar as predições como \"Avaliação Positiva\" ou \"Avaliação Negativa\" ao invés de \"1\" ou \"0\", facilitando a visualização da resposta para qualquer frase arbitrária. Também verificamos, por meio do modelo, **quais palavras possuem maior correlação** com as categorias positiva e negativa.\n",
    "\n",
    "Utilizando um dataset de teste, foi possível também testar o modelo nos comentários e verificar qual classe deveria ter sido escolhida. Isso nos permitiu **calcular acurácia, F1, AUC e criar uma matriz de confusão** para os dados de teste.\n",
    "\n",
    "# Código\n",
    "Durante a criação do código, importamos as bibliotecas `numpy` e `nltk` (Natural Language Toolkit), além do `sklearn` (Scikit Learn) e `pandas`. Para o `nltk`, utilizamos os `stopwords`, `punkt` (pontuação) e `rslp` (o Stemmer \"Removedor de Sufixos da Lingua Portuguesa\").\n",
    "Também utilizamos um corpus das stopwords em português com adição dos meses, e abreviações específicas para o idioma português, pois alguns autores de comentários optaram por escrever palavras abreviadamente.\n",
    "\n",
    "Uma busca exaustiva para um estimador foi feita com o método [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) do `sklearn`, que cria uma pipeline (sequência de métodos) com `tfidf` e `classifier`. Por padrão utilizamos 4 cores, mas o valor `-1` permite paralelismo ótimo de acordo com a configuração do computador que executa o programa. Quando executado em um Docker container, houve a necessidade de aumentar a memória para evitar erros durante a execução.\n",
    "\n",
    "# Conclusões\n",
    "A geração do modelo foi a parte mais custosa em termos computacionais do trabalho, podendo levar mais de 10 minutos. Porém após essa etapa obtemos resultados compensatórios: o modelo obteve acurácia, F1 e AUC > 0.9 no conjunto de teste. Ele foi especialmente capaz de detectar avaliações positivas com alta precisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pichau\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Pichau\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\Pichau\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Importação de bibliotecas, download de recursos e definição de variáveis globais (stopwords e dicionario para corrigir abreviações)\n",
    "\n",
    "#!pip install os\n",
    "import os\n",
    "#!pip install pandas\n",
    "import pandas as pd\n",
    "#!pip install numpy\n",
    "import numpy as np\n",
    "#!pip install nltk\n",
    "import nltk\n",
    "#!pip install re\n",
    "import re\n",
    "#!pip install unicodedata\n",
    "import unicodedata\n",
    "#!pip install joblib\n",
    "import joblib\n",
    "#!pip install scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('rslp')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese') + ['outubro', 'novembro', 'dezembro', 'janeiro', 'fevereiro', 'marco', 'abril', 'maio', 'junho', 'julho', 'agosto', 'setembro', ' ']\n",
    "abreviacoes = {'mt':'muito', 'mto':'muito', 'dms':'demais', 'fds':'fim de semana', 'blz':'beleza', 'bls':'beleza'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição de funções para pré-processamento\n",
    "\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "def stemming(lista):\n",
    "    retorno = []\n",
    "    for word in lista:\n",
    "        retorno.append(stemmer.stem(word))\n",
    "    return retorno\n",
    "\n",
    "def ajusta_abreviacoes(lista):\n",
    "    retorno = []\n",
    "    for word in lista:\n",
    "        if word in list(abreviacoes.keys()):\n",
    "            retorno.append(abreviacoes[word])\n",
    "        else:\n",
    "            retorno.append(word)\n",
    "    return retorno\n",
    "\n",
    "def ajusta_letras(lista):\n",
    "    retorno = []\n",
    "    for word in lista:\n",
    "        palavra = list(word)\n",
    "        palavra_certa = []\n",
    "        for i in range(len(palavra)):\n",
    "            letra = palavra[i]\n",
    "            if i == len(palavra)-1:\n",
    "                letra_prox='_FIM_'\n",
    "            else:\n",
    "                letra_prox = palavra[i+1]\n",
    "            \n",
    "            if letra != letra_prox or letra in ['s', 'r']:\n",
    "                palavra_certa.append(letra)\n",
    "        retorno.append(''.join(palavra_certa))\n",
    "            \n",
    "    return retorno\n",
    "\n",
    "    \n",
    "def preprocessamento(texto):\n",
    "    #Removendo acentos e maiúsculas...\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ASCII','ignore').decode('ASCII').lower()\n",
    "    #Substituindo e-mails por token indicativo...\n",
    "    texto = re.sub(r'([a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)', '_EMAIL_', texto)\n",
    "    #Substituindo pontuações por espaços (evitar encavalamento de palavras)...\n",
    "    texto = re.sub(r'[,.;:\\(\\)]', ' ', texto)\n",
    "    #Removendo numeros e caracteres especiais...\n",
    "    texto = re.sub(r'[^a-z\\s]', '', texto)\n",
    "    #Tokenização...\n",
    "    tokens = nltk.tokenize.word_tokenize(texto)\n",
    "    #Removendo letras soltas...\n",
    "    tokens = [token for token in tokens if len(token) > 1]\n",
    "    #Ajustando palavras com letras a mais:\n",
    "    tokens = ajusta_letras(tokens)\n",
    "    #Ajustando abreviações...\n",
    "    tokens = ajusta_abreviacoes(tokens)\n",
    "    #Removendo stopwords...\n",
    "    tokens_sw = [token for token in tokens if token not in stopwords]\n",
    "    #Aplicando Stemming RLSP\n",
    "    tokens_sw = stemming(tokens_sw)\n",
    "    return ' '.join(tokens_sw)\n",
    "\n",
    "def preprocessarbase(base, coluna): #Executa o pré-processamento a todos os textos de uma base de dados\n",
    "    base[coluna] = base[coluna].apply(preprocessamento)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_brand</th>\n",
       "      <th>site_category_lv1</th>\n",
       "      <th>site_category_lv2</th>\n",
       "      <th>review_title</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>recommend_to_a_friend</th>\n",
       "      <th>review_text</th>\n",
       "      <th>reviewer_birth_year</th>\n",
       "      <th>reviewer_gender</th>\n",
       "      <th>reviewer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:11:28</td>\n",
       "      <td>d0fb1ca69422530334178f5c8624aa7a99da47907c44de...</td>\n",
       "      <td>132532965.0</td>\n",
       "      <td>Notebook Asus Vivobook Max X541NA-GO472T Intel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Informática</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>Bom</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Estou contente com a compra entrega rápida o ú...</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>F</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:13:48</td>\n",
       "      <td>014d6dc5a10aed1ff1e6f349fb2b059a2d3de511c7538a...</td>\n",
       "      <td>22562178.0</td>\n",
       "      <td>Copo Acrílico Com Canudo 500ml Rocie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Utilidades Domésticas</td>\n",
       "      <td>Copos, Taças e Canecas</td>\n",
       "      <td>Preço imbatível, ótima qualidade</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Por apenas R$1994.20,eu consegui comprar esse ...</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>M</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:26:02</td>\n",
       "      <td>44f2c8edd93471926fff601274b8b2b5c4824e386ae4f2...</td>\n",
       "      <td>113022329.0</td>\n",
       "      <td>Panela de Pressão Elétrica Philips Walita Dail...</td>\n",
       "      <td>philips walita</td>\n",
       "      <td>Eletroportáteis</td>\n",
       "      <td>Panela Elétrica</td>\n",
       "      <td>ATENDE TODAS AS EXPECTATIVA.</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>M</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:35:54</td>\n",
       "      <td>ce741665c1764ab2d77539e18d0e4f66dde6213c9f0863...</td>\n",
       "      <td>113851581.0</td>\n",
       "      <td>Betoneira Columbus - Roma Brinquedos</td>\n",
       "      <td>roma jensen</td>\n",
       "      <td>Brinquedos</td>\n",
       "      <td>Veículos de Brinquedo</td>\n",
       "      <td>presente mais que desejado</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>F</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 01:00:28</td>\n",
       "      <td>7d7b6b18dda804a897359276cef0ca252f9932bf4b5c8e...</td>\n",
       "      <td>131788803.0</td>\n",
       "      <td>Smart TV LED 43\" LG 43UJ6525 Ultra HD 4K com C...</td>\n",
       "      <td>lg</td>\n",
       "      <td>TV e Home Theater</td>\n",
       "      <td>TV</td>\n",
       "      <td>Sem duvidas, excelente</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A entrega foi no prazo, as americanas estão de...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>M</td>\n",
       "      <td>MG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_date                                        reviewer_id  \\\n",
       "0 2018-01-01 00:11:28  d0fb1ca69422530334178f5c8624aa7a99da47907c44de...   \n",
       "1 2018-01-01 00:13:48  014d6dc5a10aed1ff1e6f349fb2b059a2d3de511c7538a...   \n",
       "2 2018-01-01 00:26:02  44f2c8edd93471926fff601274b8b2b5c4824e386ae4f2...   \n",
       "3 2018-01-01 00:35:54  ce741665c1764ab2d77539e18d0e4f66dde6213c9f0863...   \n",
       "4 2018-01-01 01:00:28  7d7b6b18dda804a897359276cef0ca252f9932bf4b5c8e...   \n",
       "\n",
       "    product_id                                       product_name  \\\n",
       "0  132532965.0  Notebook Asus Vivobook Max X541NA-GO472T Intel...   \n",
       "1   22562178.0               Copo Acrílico Com Canudo 500ml Rocie   \n",
       "2  113022329.0  Panela de Pressão Elétrica Philips Walita Dail...   \n",
       "3  113851581.0               Betoneira Columbus - Roma Brinquedos   \n",
       "4  131788803.0  Smart TV LED 43\" LG 43UJ6525 Ultra HD 4K com C...   \n",
       "\n",
       "    product_brand      site_category_lv1       site_category_lv2  \\\n",
       "0             NaN            Informática                Notebook   \n",
       "1             NaN  Utilidades Domésticas  Copos, Taças e Canecas   \n",
       "2  philips walita        Eletroportáteis         Panela Elétrica   \n",
       "3     roma jensen             Brinquedos   Veículos de Brinquedo   \n",
       "4              lg      TV e Home Theater                      TV   \n",
       "\n",
       "                       review_title  overall_rating recommend_to_a_friend  \\\n",
       "0                               Bom               4                   Yes   \n",
       "1  Preço imbatível, ótima qualidade               4                   Yes   \n",
       "2      ATENDE TODAS AS EXPECTATIVA.               4                   Yes   \n",
       "3        presente mais que desejado               4                   Yes   \n",
       "4            Sem duvidas, excelente               5                   Yes   \n",
       "\n",
       "                                         review_text  reviewer_birth_year  \\\n",
       "0  Estou contente com a compra entrega rápida o ú...               1958.0   \n",
       "1  Por apenas R$1994.20,eu consegui comprar esse ...               1996.0   \n",
       "2  SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...               1984.0   \n",
       "3  MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...               1985.0   \n",
       "4  A entrega foi no prazo, as americanas estão de...               1994.0   \n",
       "\n",
       "  reviewer_gender reviewer_state  \n",
       "0               F             RJ  \n",
       "1               M             SC  \n",
       "2               M             SP  \n",
       "3               F             SP  \n",
       "4               M             MG  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reconhecimento dos caminhos utilizados e importação da base\n",
    "\n",
    "path = os.getcwd() + '\\\\'\n",
    "path_base = path + 'Bases\\\\'\n",
    "path_auxiliar = path+ 'Auxiliar\\\\'\n",
    "base_dados = pd.read_excel(path_base + 'dados_americanas.xlsx')\n",
    "\n",
    "base_dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>Classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estou contente com a compra entrega rápida o ú...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Por apenas R$1994.20,eu consegui comprar esse ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A entrega foi no prazo, as americanas estão de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116053</th>\n",
       "      <td>Vale muito, estou usando no controle do Xbox e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116054</th>\n",
       "      <td>Prático e barato, super indico o produto para ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116055</th>\n",
       "      <td>Chegou antes do prazo previsto e corresponde a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116056</th>\n",
       "      <td>Material fraco, poderia ser melhor. Ficou deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116057</th>\n",
       "      <td>Comprei esse produto, quando chegou estava com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116058 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Texto  Classe\n",
       "0       Estou contente com a compra entrega rápida o ú...       1\n",
       "1       Por apenas R$1994.20,eu consegui comprar esse ...       1\n",
       "2       SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...       1\n",
       "3       MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...       1\n",
       "4       A entrega foi no prazo, as americanas estão de...       1\n",
       "...                                                   ...     ...\n",
       "116053  Vale muito, estou usando no controle do Xbox e...       1\n",
       "116054  Prático e barato, super indico o produto para ...       1\n",
       "116055  Chegou antes do prazo previsto e corresponde a...       1\n",
       "116056  Material fraco, poderia ser melhor. Ficou deve...       0\n",
       "116057  Comprei esse produto, quando chegou estava com...       0\n",
       "\n",
       "[116058 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tratamento da base e geração de classes binárias\n",
    "\n",
    "base_dados = base_dados[base_dados['overall_rating'] != 3].reset_index(drop=True)\n",
    "base_dados['Classe'] = np.where(base_dados['overall_rating'] > 3, 1, 0)\n",
    "\n",
    "base_dados.drop(['submission_date', 'reviewer_id', 'product_id', 'product_name', 'product_brand', 'site_category_lv1', 'site_category_lv2', 'review_title', 'overall_rating', 'recommend_to_a_friend', 'reviewer_birth_year', 'reviewer_gender', 'reviewer_state'],axis=1,inplace=True)\n",
    "base_dados.rename(columns={'review_text':'Texto'}, inplace=True)\n",
    "\n",
    "base_dados #retorna a base já tratada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio do pré-processamento dos dados...\n",
      "Pré-processamento finalizado. Tempo decorrido: 89.96394896507263 segundos.\n"
     ]
    }
   ],
   "source": [
    "#Execução do pré-processamento dos textos da base, com visualização do tempo gasto\n",
    "\n",
    "from time import time\n",
    "print(\"Inicio do pré-processamento dos dados...\")\n",
    "inicio = time()\n",
    "base_preproc = base_dados.copy(deep=True)\n",
    "preprocessarbase(base_preproc, 'Texto')\n",
    "fim = time()\n",
    "print(\"Pré-processamento finalizado. Tempo decorrido: \" + str(fim-inicio) + \" segundos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>Classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cont compr entreg rap unic problem americ troc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apen consegu compr lind cop acril</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sup agil pratic outr panel eletr costum us out...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filh amou parec verdad tant detalh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entreg praz americ esta parab smart tv boa nav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116053</th>\n",
       "      <td>val us control xbox dur seman carg par jog tod...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116054</th>\n",
       "      <td>pra barat sup indic produt corr dia dia praz e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116055</th>\n",
       "      <td>cheg ant praz previst correspond anunci</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116056</th>\n",
       "      <td>mater frac pod ser melhor fic dev opinia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116057</th>\n",
       "      <td>compr produt cheg av devolv ja vai faz mes nao...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116058 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Texto  Classe\n",
       "0       cont compr entreg rap unic problem americ troc...       1\n",
       "1                       apen consegu compr lind cop acril       1\n",
       "2       sup agil pratic outr panel eletr costum us out...       1\n",
       "3                      filh amou parec verdad tant detalh       1\n",
       "4       entreg praz americ esta parab smart tv boa nav...       1\n",
       "...                                                   ...     ...\n",
       "116053  val us control xbox dur seman carg par jog tod...       1\n",
       "116054  pra barat sup indic produt corr dia dia praz e...       1\n",
       "116055            cheg ant praz previst correspond anunci       1\n",
       "116056           mater frac pod ser melhor fic dev opinia       0\n",
       "116057  compr produt cheg av devolv ja vai faz mes nao...       0\n",
       "\n",
       "[116058 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Envio da base pré-processada para um arquivo excel\n",
    "base_preproc.to_excel(path_base+'Base_Final.xlsx')\n",
    "base_preproc #retorna a base pré-processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=4)]: Done 120 out of 120 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(min_df=20,\n",
       "                                                        ngram_range=(1, 3))),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(max_iter=200000))]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'classifier__C': array([1.00000000e-04, 7.74263683e-04, 5.99484250e-03, 4.64158883e-02,\n",
       "       3.59381366e-01, 2.78255940e+00, 2.15443469e+01, 1.66810054e+02,\n",
       "       1.29154967e+03, 1.00000000e+04]),\n",
       "                         'classifier__penalty': ['l1', 'l2'],\n",
       "                         'classifier__solver': ['sag', 'lbfgs']},\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importação de funções específicas da biblioteca sklearn, definição de parâmetros para busca exaustiva (GridSearchCV) \n",
    "#e realização da mesma\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid ={\n",
    "    'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 10),\n",
    "    'classifier__solver' : ['sag', 'lbfgs'],\n",
    "}\n",
    "\n",
    "pipe = Pipeline(steps=[('tfidf', TfidfVectorizer(min_df=20, ngram_range=(1,3))),\n",
    "                       ('classifier', LogisticRegression(max_iter = 200000))])\n",
    "\n",
    "gridsearch = GridSearchCV(pipe, param_grid=param_grid, cv = 3, n_jobs=4, scoring='f1', verbose=3)\n",
    "\n",
    "gridsearch.fit(base_preproc['Texto'], base_preproc['Classe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Pichau\\\\Documents\\\\Faculdade\\\\Projeto2_PLN\\\\Auxiliar\\\\modelo.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Escolha do melhor modelo (de acordo com o F1 score) e salvamento dele em arquivo .pkl para agilizar eventuais testes etc.\n",
    "\n",
    "model = gridsearch.best_estimator_\n",
    "joblib.dump(model, path_auxiliar+'modelo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menores coeficientes:\n",
      "['nao recom' 'nao' 'pess' 'nao func' 'ruim' 'nao gost' 'horri' 'decepcion'\n",
      " 'frac' 'insatisfeit']\n",
      "\n",
      "Maiores coeficientes: \n",
      "['otim' 'excel' 'recom' 'ador' 'bom' 'perfeit' 'satisfeit' 'ame'\n",
      " 'maravilh' 'gost']\n",
      "\n",
      "F1 Score do modelo: \n",
      "0.9631607919291493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Visualização da correlação de palavras/termos com as classes positiva (maiores coeficientes) e negativa (menores coeficientes)\n",
    "\n",
    "sorted_coef_index = model['classifier'].coef_[0].argsort()\n",
    "feature_names = np.array(model['tfidf'].get_feature_names())\n",
    "\n",
    "print('Menores coeficientes:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Maiores coeficientes: \\n{}\\n'.format(feature_names[sorted_coef_index[:-11:-1]]))\n",
    "print('F1 Score do modelo: \\n{}\\n'.format(gridsearch.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para traduzir 0 ou 1 em Avaliação Negativa ou Avaliação Positiva\n",
    "\n",
    "dic_modelo = {0:'Avaliação Negativa', 1:'Avaliação Positiva'}\n",
    "def avaliacao_produto(frase):\n",
    "    if type(frase) == str:\n",
    "        return dic_modelo[model.predict([preprocessamento(frase)])[0]]\n",
    "    else:\n",
    "        retorno = ''\n",
    "        preproc = pd.DataFrame(columns=['Texto'])\n",
    "        preproc['Texto'] = frase\n",
    "        preprocessarbase(preproc, 'Texto')\n",
    "        predicoes = model.predict(preproc['Texto'])\n",
    "        for predicao in predicoes:\n",
    "            retorno += dic_modelo[predicao] + '\\n'\n",
    "        return retorno\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliação Positiva\n"
     ]
    }
   ],
   "source": [
    "#Teste da função definida acima\n",
    "print(avaliacao_produto('Adorei o produto!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação e tratamento de base para testagem do modelo (para facilitar o cálculo das métricas, utilizamos as predições\n",
    "#diretas modelo, em 0 e 1, ao invés de passá-las pela tradução)\n",
    "\n",
    "teste = pd.read_csv(path_base+'teste_dataset.csv').drop(columns=['review_id', 'order_id', 'review_comment_title', 'review_creation_date', 'review_answer_timestamp'], axis=1).dropna(axis=0).reset_index(drop=True)\n",
    "teste = teste[teste['review_score'] != 3].rename(columns={'review_comment_message': 'Texto'})\n",
    "\n",
    "teste['Classificacao'] = np.where(teste['review_score']>3, 1, 0)\n",
    "teste.drop('review_score', axis=1, inplace=True)\n",
    "preprocessarbase(teste, 'Texto')\n",
    "predict = model.predict(teste['Texto']) #armazena predições do modelo para a base de teste na variável \"predict\"\n",
    "real = teste['Classificacao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para testar o modelo com base nas classes reais e nas preditas. Exibe diferentes métricas (acurácia, F1 score e AUC \n",
    "#score) e a matriz de confusão do modelo\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "def matriz_confusão(real, pred):\n",
    "    retorno = pd.DataFrame(confusion_matrix(real, pred), index=['Real: Avaliação Negativa', 'Real: Avaliação Positiva'])\n",
    "    retorno.rename(columns={0:'Pred: Avaliação Negativa', 1:'Pred: Avaliação Positiva'}, inplace=True)\n",
    "    print('A acurácia do modelo nos testes foi de {}\\n'.format(accuracy_score(real, pred)))\n",
    "    print('O F1 Score do modelo nos testes foi de {}\\n'.format(f1_score(real, pred)))\n",
    "    print('O AUC Score do modelo nos testes foi de {}\\n'.format(roc_auc_score(real, pred)))\n",
    "    return retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo nos testes foi de 0.9257246376811594\n",
      "\n",
      "O F1 Score do modelo nos testes foi de 0.9465934190406071\n",
      "\n",
      "O AUC Score do modelo nos testes foi de 0.9163750785897374\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred: Avaliação Negativa</th>\n",
       "      <th>Pred: Avaliação Positiva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real: Avaliação Negativa</th>\n",
       "      <td>10188</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real: Avaliação Positiva</th>\n",
       "      <td>1609</td>\n",
       "      <td>25071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Pred: Avaliação Negativa  Pred: Avaliação Positiva\n",
       "Real: Avaliação Negativa                     10188                      1220\n",
       "Real: Avaliação Positiva                      1609                     25071"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Executa a função acima com os dados da base de teste\n",
    "matriz_confusão(real, predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
